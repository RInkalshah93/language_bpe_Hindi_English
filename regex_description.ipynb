{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT4_SPLIT_PATTERN = r\"\"\"'(?i:[sdmt]|ll|ve|re)|[^\\r\\n\\p{L}\\p{N}]?+\\p{L}+|\\p{N}{1,3}| ?[^\\s\\p{L}\\p{N}]++[\\r\\n]*|\\s*[\\r\\n]|\\s+(?!\\S)|\\s+\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_pattern = re.compile(GPT4_SPLIT_PATTERN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regex group '(?i:[sdmt]|ll|ve|re)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split 's. e.g it's --> it 's , he's --> he 's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yeah', ',', ' I', ' think', ' it', \"'s\", ' a', ' good', ' environment', ' for', ' learning', ' English', '.']\n"
     ]
    }
   ],
   "source": [
    "text = \"Yeah, I think it's a good environment for learning English.\"\n",
    "# split the text up into text chunks\n",
    "text_chunks = re.findall(compiled_pattern, text)    \n",
    "print(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['हाँ', ' मुझे', ' लग', 'ता', ' है', ' कि', ' यह', ' अंग्रेजी', ' सीख', 'ने', ' के', ' लिए', ' एक', ' अच्छा', ' वातावरण', ' है']\n"
     ]
    }
   ],
   "source": [
    "text = \"हाँ, मुझे लगता है कि यह अंग्रेजी सीखने के लिए एक अच्छा वातावरण है।\"\n",
    "HINDI_SPLIT_PATTERN = r'[^\\r\\n\\p{L}\\p{N}]?+[\\p{L}\\p{M}]+'\n",
    "HINDI_WORD_SPLIT_PATTERN = r'([\\s\\p{L}\\p{M}]{2,})([तन](?:\\p{M}))$'\n",
    "hindi_compiled_pattern = re.compile(HINDI_SPLIT_PATTERN)\n",
    "hindi_compiled_pattern_word = re.compile(HINDI_WORD_SPLIT_PATTERN)\n",
    "text_chunks = re.findall(hindi_compiled_pattern, text)\n",
    "text_chunks_element = []\n",
    "for chunk in text_chunks:\n",
    "    element_chunks = re.findall(hindi_compiled_pattern_word, chunk)\n",
    "    if element_chunks == []:\n",
    "        text_chunks_element.append(chunk) \n",
    "    else:\n",
    "        text_chunks_element.extend(element_chunks[0]) \n",
    "print(text_chunks_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split 'd. e.g i'd --> i 's , he'd --> he 'd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', \"'d\", ' rather', ' be', ' a', ' bird', ' than', ' a', ' fish', '.']\n"
     ]
    }
   ],
   "source": [
    "text = \"I'd rather be a bird than a fish.\"\n",
    "# split the text up into text chunks\n",
    "text_chunks = re.findall(compiled_pattern, text)\n",
    "print(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['मैं', ' मछली', ' की', ' बजाय', ' पक्षी', ' बन', 'ना', ' पसंद', ' करूं', 'गा']\n"
     ]
    }
   ],
   "source": [
    "text = \"मैं मछली की बजाय पक्षी बनना पसंद करूंगा।\"\n",
    "HINDI_SPLIT_PATTERN = r'[^\\r\\n\\p{L}\\p{N}]?+[\\p{L}\\p{M}]+'\n",
    "HINDI_WORD_SPLIT_PATTERN = r'([\\s\\p{L}\\p{M}]{2,})([गतन](?:\\p{M}))$'\n",
    "hindi_compiled_pattern = re.compile(HINDI_SPLIT_PATTERN)\n",
    "hindi_compiled_pattern_word = re.compile(HINDI_WORD_SPLIT_PATTERN)\n",
    "text_chunks = re.findall(hindi_compiled_pattern, text)\n",
    "text_chunks_element = []\n",
    "for chunk in text_chunks:\n",
    "    element_chunks = re.findall(hindi_compiled_pattern_word, chunk)\n",
    "    if element_chunks == []:\n",
    "        text_chunks_element.append(chunk) \n",
    "    else:\n",
    "        text_chunks_element.extend(element_chunks[0]) \n",
    "print(text_chunks_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split 'm. e.g i'm --> i 'm , I'm --> I 'm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', \"'m\", ' planning', ' to', ' write', ' a', ' book', ' someday', '.']\n"
     ]
    }
   ],
   "source": [
    "text = \"I'm planning to write a book someday.\"\n",
    "# split the text up into text chunks\n",
    "text_chunks = re.findall(compiled_pattern, text)\n",
    "print(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['मैं', ' किसी', ' दिन', ' एक', ' किताब', ' लिख', 'ने', ' की', ' योज', 'ना', ' ब', 'ना', ' रहा', ' हूं']\n"
     ]
    }
   ],
   "source": [
    "text = \"मैं किसी दिन एक किताब लिखने की योजना बना रहा हूं।\"\n",
    "HINDI_SPLIT_PATTERN = r'[^\\r\\n\\p{L}\\p{N}]?+[\\p{L}\\p{M}]+'\n",
    "HINDI_WORD_SPLIT_PATTERN = r'([\\s\\p{L}\\p{M}]{2,})([गतन](?:\\p{M}))$'\n",
    "hindi_compiled_pattern = re.compile(HINDI_SPLIT_PATTERN)\n",
    "hindi_compiled_pattern_word = re.compile(HINDI_WORD_SPLIT_PATTERN)\n",
    "text_chunks = re.findall(hindi_compiled_pattern, text)\n",
    "text_chunks_element = []\n",
    "for chunk in text_chunks:\n",
    "    element_chunks = re.findall(hindi_compiled_pattern_word, chunk)\n",
    "    if element_chunks == []:\n",
    "        text_chunks_element.append(chunk) \n",
    "    else:\n",
    "        text_chunks_element.extend(element_chunks[0]) \n",
    "print(text_chunks_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split 't. e.g didn't --> didn 't , isn't --> isn 't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', ' hawk', ' didn', '’t', ' understand', ' why', ' the', ' ground', ' squirrels', ' didn', '’t', ' want', ' to', ' be', ' his', ' friend', '.']\n"
     ]
    }
   ],
   "source": [
    "text = \"The hawk didn’t understand why the ground squirrels didn’t want to be his friend.\"\n",
    "# split the text up into text chunks\n",
    "text_chunks = re.findall(compiled_pattern, text)\n",
    "print(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['बाज', ' को', ' समझ', ' नहीं', ' आया', ' कि', ' ज़मी', 'नी', ' गिलहरियाँ', ' उस', 'की', ' दोस्त', ' क्यों', ' नहीं', ' बन', 'ना', ' चाह', 'तीं']\n"
     ]
    }
   ],
   "source": [
    "text = \"बाज को समझ नहीं आया कि ज़मीनी गिलहरियाँ उसकी दोस्त क्यों नहीं बनना चाहतीं।\"\n",
    "HINDI_SPLIT_PATTERN = r'[^\\r\\n\\p{L}\\p{N}]?+[\\p{L}\\p{M}]+'\n",
    "HINDI_WORD_SPLIT_PATTERN = r'([\\s\\p{L}\\p{M}]{2,})([कगतन](?:\\p{M}+))$'\n",
    "hindi_compiled_pattern = re.compile(HINDI_SPLIT_PATTERN)\n",
    "hindi_compiled_pattern_word = re.compile(HINDI_WORD_SPLIT_PATTERN)\n",
    "text_chunks = re.findall(hindi_compiled_pattern, text)\n",
    "text_chunks_element = []\n",
    "for chunk in text_chunks:\n",
    "    element_chunks = re.findall(hindi_compiled_pattern_word, chunk)\n",
    "    if element_chunks == []:\n",
    "        text_chunks_element.append(chunk) \n",
    "    else:\n",
    "        text_chunks_element.extend(element_chunks[0]) \n",
    "print(text_chunks_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split 'll. e.g she'll --> she 'll , he'll --> he 'll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['She', \"'ll\", ' think', ' you', ' cared', ' more', ' about', ' your', ' frizzles', ' than', ' your', ' friends', '.']\n"
     ]
    }
   ],
   "source": [
    "text = \"She'll think you cared more about your frizzles than your friends.\"\n",
    "# split the text up into text chunks\n",
    "text_chunks = re.findall(compiled_pattern, text)\n",
    "print(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['वह', ' सोचे', 'गी', ' कि', ' आप', 'को', ' अप', 'ने', ' दोस्तों', ' की', ' तुल', 'ना', ' में', ' अप', 'ने', ' बालों', ' की', ' अधिक', ' परवाह', ' है']\n"
     ]
    }
   ],
   "source": [
    "text = \"वह सोचेगी कि आपको अपने दोस्तों की तुलना में अपने बालों की अधिक परवाह है।\"\n",
    "HINDI_SPLIT_PATTERN = r'[^\\r\\n\\p{L}\\p{N}]?+[\\p{L}\\p{M}]+'\n",
    "HINDI_WORD_SPLIT_PATTERN = r'([\\s\\p{L}\\p{M}]{2,})([कगतन](?:\\p{M}))$'\n",
    "hindi_compiled_pattern = re.compile(HINDI_SPLIT_PATTERN)\n",
    "hindi_compiled_pattern_word = re.compile(HINDI_WORD_SPLIT_PATTERN)\n",
    "text_chunks = re.findall(hindi_compiled_pattern, text)\n",
    "text_chunks_element = []\n",
    "for chunk in text_chunks:\n",
    "    element_chunks = re.findall(hindi_compiled_pattern_word, chunk)\n",
    "    if element_chunks == []:\n",
    "        text_chunks_element.append(chunk) \n",
    "    else:\n",
    "        text_chunks_element.extend(element_chunks[0]) \n",
    "print(text_chunks_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split 've. e.g i've --> i 've , he've --> he 've"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['For', ' lunch', ' I', ' like', ' fried', ' onions', ',', ' which', ' I', \"'ve\", ' eaten', ' for', ' as', ' long', ' as', ' I', ' can', ' remember']\n"
     ]
    }
   ],
   "source": [
    "text = \"For lunch I like fried onions, which I've eaten for as long as I can remember\"\n",
    "# split the text up into text chunks\n",
    "text_chunks = re.findall(compiled_pattern, text)\n",
    "print(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['दोपहर', ' के', ' भोजन', ' के', ' लिए', ' मुझे', ' तले', ' हुए', ' प्याज', ' पसंद', ' हैं', ' जिन्हें', ' मैं', ' जहां', ' तक', ' याद', ' है', ' खा', 'ता', ' रहा', ' हूं']\n"
     ]
    }
   ],
   "source": [
    "text = \"दोपहर के भोजन के लिए मुझे तले हुए प्याज पसंद हैं, जिन्हें मैं जहां तक याद है, खाता रहा हूं।\"\n",
    "HINDI_SPLIT_PATTERN = r'[^\\r\\n\\p{L}\\p{N}]?+[\\p{L}\\p{M}]+'\n",
    "HINDI_WORD_SPLIT_PATTERN = r'([\\s\\p{L}\\p{M}]{2,})([कगतन](?:\\p{M}))$'\n",
    "hindi_compiled_pattern = re.compile(HINDI_SPLIT_PATTERN)\n",
    "hindi_compiled_pattern_word = re.compile(HINDI_WORD_SPLIT_PATTERN)\n",
    "text_chunks = re.findall(hindi_compiled_pattern, text)\n",
    "text_chunks_element = []\n",
    "for chunk in text_chunks:\n",
    "    element_chunks = re.findall(hindi_compiled_pattern_word, chunk)\n",
    "    if element_chunks == []:\n",
    "        text_chunks_element.append(chunk) \n",
    "    else:\n",
    "        text_chunks_element.extend(element_chunks[0]) \n",
    "print(text_chunks_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate new line charater (\\n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Getting', ' up', ' at', ' dawn', ' is', ' for', ' the', ' \\n', 'birds', '.']\n"
     ]
    }
   ],
   "source": [
    "text = \"Getting up at dawn is for the \\nbirds.\"\n",
    "# split the text up into text chunks\n",
    "text_chunks = re.findall(compiled_pattern, text)\n",
    "print(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['भोर', ' में', ' उठ', 'ना', ' पक्षियों', ' के', ' लिए', 'है']\n"
     ]
    }
   ],
   "source": [
    "text = \"भोर में उठना पक्षियों के लिए \\nहै।\"\n",
    "HINDI_SPLIT_PATTERN = r'[^\\r\\n\\p{L}\\p{N}]?+[\\p{L}\\p{M}]+'\n",
    "HINDI_WORD_SPLIT_PATTERN = r'([\\s\\p{L}\\p{M}]{2,})([कगतन](?:[ेाीो]))$'\n",
    "hindi_compiled_pattern = re.compile(HINDI_SPLIT_PATTERN)\n",
    "hindi_compiled_pattern_word = re.compile(HINDI_WORD_SPLIT_PATTERN)\n",
    "text_chunks = re.findall(hindi_compiled_pattern, text)\n",
    "text_chunks_element = []\n",
    "for chunk in text_chunks:\n",
    "    element_chunks = re.findall(hindi_compiled_pattern_word, chunk)\n",
    "    if element_chunks == []:\n",
    "        text_chunks_element.append(chunk) \n",
    "    else:\n",
    "        text_chunks_element.extend(element_chunks[0]) \n",
    "print(text_chunks_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split numbers from words and split numbers with length greater than 3 e.g l8H --> l 8 H , H7876R --> H 787 6 R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dEjqH', '787', '6', 'Re', '7', 'HlUJ', '8', 'J', '14']\n"
     ]
    }
   ],
   "source": [
    "text = \"dEjqH7876Re7HlUJ8J14\"\n",
    "# split the text up into text chunks\n",
    "text_chunks = re.findall(compiled_pattern, text)\n",
    "print(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['भोर', ' में', ' उठ', 'ना', ' पक्षियों', ' के', ' लिए', ' मैं', '8८', 'एच', ' एच', '787', '6७८', '७६', 'हैं', ' है']\n"
     ]
    }
   ],
   "source": [
    "text = \"भोर में उठना पक्षियों के लिए मैं8८एच एच7876७८७६हैं है।\"\n",
    "HINDI_SPLIT_PATTERN = r'[^\\r\\n\\p{L}\\p{N}]?+[\\p{L}\\p{M}]+|\\p{N}{1,3}'\n",
    "HINDI_WORD_SPLIT_PATTERN = r'([\\s\\p{L}\\p{M}]{2,})([कगतन](?:[ेाीो]))$'\n",
    "hindi_compiled_pattern = re.compile(HINDI_SPLIT_PATTERN)\n",
    "hindi_compiled_pattern_word = re.compile(HINDI_WORD_SPLIT_PATTERN)\n",
    "text_chunks = re.findall(hindi_compiled_pattern, text)\n",
    "text_chunks_element = []\n",
    "for chunk in text_chunks:\n",
    "    element_chunks = re.findall(hindi_compiled_pattern_word, chunk)\n",
    "    if element_chunks == []:\n",
    "        text_chunks_element.append(chunk) \n",
    "    else:\n",
    "        text_chunks_element.extend(element_chunks[0]) \n",
    "print(text_chunks_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split new line characters e.g \\n\\nabc --> \\n\\n abc , \\n\\nxyz --> \\n\\n xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Her', ' daily', ' goal', ' was', ' to', ' improve', ' on', ' \\n\\n', 'yesterday', '.']\n"
     ]
    }
   ],
   "source": [
    "text = \"Her daily goal was to improve on \\n\\nyesterday.\"\n",
    "# split the text up into text chunks\n",
    "text_chunks = re.findall(compiled_pattern, text)\n",
    "print(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['उस', 'का', ' दैनिक', ' लक्ष्य', ' कल', ' में', ' सुधार', ' कर', 'ना', ' \\n\\n', 'था', '।']\n"
     ]
    }
   ],
   "source": [
    "text = \"उसका दैनिक लक्ष्य कल में सुधार करना \\n\\nथा।\"\n",
    "HINDI_SPLIT_PATTERN = r'[^\\r\\n\\p{L}\\p{N}]?+[\\p{L}\\p{M}]+|\\p{N}{1,3}| ?[^\\s\\p{L}\\p{N}]++[\\r\\n]*|\\s*[\\r\\n]'\n",
    "HINDI_WORD_SPLIT_PATTERN = r'([\\s\\p{L}\\p{M}]{2,})([कगतन](?:[ेाीो]))$'\n",
    "hindi_compiled_pattern = re.compile(HINDI_SPLIT_PATTERN)\n",
    "hindi_compiled_pattern_word = re.compile(HINDI_WORD_SPLIT_PATTERN)\n",
    "text_chunks = re.findall(hindi_compiled_pattern, text)\n",
    "text_chunks_element = []\n",
    "for chunk in text_chunks:\n",
    "    element_chunks = re.findall(hindi_compiled_pattern_word, chunk)\n",
    "    if element_chunks == []:\n",
    "        text_chunks_element.append(chunk) \n",
    "    else:\n",
    "        text_chunks_element.extend(element_chunks[0]) \n",
    "print(text_chunks_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split multiple spaces in front of a word by keeping one space with that word e.g ....street --> ... .street here space( ) is represented by dot(.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It', \"'s\", ' not', ' often', ' you', ' find', ' a', ' soggy', ' banana', ' on', ' the', '   ', ' street', '.']\n"
     ]
    }
   ],
   "source": [
    "text = \"It's not often you find a soggy banana on the    street.\"\n",
    "# split the text up into text chunks\n",
    "text_chunks = re.findall(compiled_pattern, text)\n",
    "print(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ऐसा', ' अक्सर', ' नहीं', ' हो', 'ता', ' है', ' कि', ' आप', 'को', ' सड़क', ' पर', ' गीला', ' केला', '   ', ' मिले', '।']\n"
     ]
    }
   ],
   "source": [
    "text = \"ऐसा अक्सर नहीं होता है कि आपको सड़क पर गीला केला    मिले।\"\n",
    "HINDI_SPLIT_PATTERN = r'[^\\r\\n\\p{L}\\p{N}]?+[\\p{L}\\p{M}]+|\\p{N}{1,3}| ?[^\\s\\p{L}\\p{N}]++[\\r\\n]*|\\s*[\\r\\n]|\\s+(?!\\S)'\n",
    "HINDI_WORD_SPLIT_PATTERN = r'([\\s\\p{L}\\p{M}]{2,})([कगतन](?:[ेाीो]))$'\n",
    "hindi_compiled_pattern = re.compile(HINDI_SPLIT_PATTERN)\n",
    "hindi_compiled_pattern_word = re.compile(HINDI_WORD_SPLIT_PATTERN)\n",
    "text_chunks = re.findall(hindi_compiled_pattern, text)\n",
    "text_chunks_element = []\n",
    "for chunk in text_chunks:\n",
    "    element_chunks = re.findall(hindi_compiled_pattern_word, chunk)\n",
    "    if element_chunks == []:\n",
    "        text_chunks_element.append(chunk) \n",
    "    else:\n",
    "        text_chunks_element.extend(element_chunks[0]) \n",
    "print(text_chunks_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is no word after multiple spaces then don't split them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['You', ' realize', ' you', \"'re\", ' not', ' alone', '.', '    ']\n"
     ]
    }
   ],
   "source": [
    "text = \"You realize you're not alone.    \"\n",
    "# split the text up into text chunks\n",
    "text_chunks = re.findall(compiled_pattern, text)\n",
    "print(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['आप', 'को', ' एहसास', ' हो', 'ता', ' है', ' कि', ' आप', ' अकेले', ' नहीं', ' हैं', '।', '    ']\n"
     ]
    }
   ],
   "source": [
    "text = \"आपको एहसास होता है कि आप अकेले नहीं हैं।    \"\n",
    "HINDI_SPLIT_PATTERN = r'[^\\r\\n\\p{L}\\p{N}]?+[\\p{L}\\p{M}]+|\\p{N}{1,3}| ?[^\\s\\p{L}\\p{N}]++[\\r\\n]*|\\s*[\\r\\n]|\\s+(?!\\S)|\\s+'\n",
    "HINDI_WORD_SPLIT_PATTERN = r'([\\s\\p{L}\\p{M}]{2,})([कगतन](?:\\p{M}))$'\n",
    "hindi_compiled_pattern = re.compile(HINDI_SPLIT_PATTERN)\n",
    "hindi_compiled_pattern_word = re.compile(HINDI_WORD_SPLIT_PATTERN)\n",
    "text_chunks = re.findall(hindi_compiled_pattern, text)\n",
    "text_chunks_element = []\n",
    "for chunk in text_chunks:\n",
    "    element_chunks = re.findall(hindi_compiled_pattern_word, chunk)\n",
    "    if element_chunks == []:\n",
    "        text_chunks_element.append(chunk) \n",
    "    else:\n",
    "        text_chunks_element.extend(element_chunks[0]) \n",
    "print(text_chunks_element)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ERA_V2_NLP",
   "language": "python",
   "name": "era_v2_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
